cli.py

import typer
from typing_extensions import Annotated
from dotenv import load_dotenv
from main import run
import os

load_dotenv()

app = typer.Typer(help="Run a DAG-based line processing pipeline with observability.")

@app.command()
def main(
    input: Annotated[
        str, 
        typer.Argument()
        ]="",
    config: Annotated[
        str,
        typer.Option(help="Path to DAG pipeline config file (YAML). Defaults to pipeline.yaml."),
    ] = "pipeline.yaml",
    output: Annotated[
        str | None,
        typer.Option(help="Specify output file. If not specified, prints to console."),
    ] = None,
    trace: Annotated[
        bool,
        typer.Option("--trace/--no-trace", help="Enable tracing of line journeys through the DAG."),
    ] = False,
    dashboard: Annotated[
        bool,
        typer.Option("--dashboard/--no-dashboard", help="Start web dashboard for live metrics (runs on http://localhost:8000)."),
    ] = True,
    dashboard_port: Annotated[
        int,
        typer.Option(help="Port for the web dashboard."),
    ] = 8000,
    max_traces: Annotated[
        int,
        typer.Option(help="Maximum number of traces to keep in memory."),
    ] = 1000,
    max_errors: Annotated[
        int,
        typer.Option(help="Maximum number of errors to keep in memory."),
    ] = 100,
):
    """
    Run a DAG pipeline on input lines. Each processor can yield tagged lines, which
    are routed according to the DAG config.
    
    The system includes built-in observability features:
    - Real-time metrics per processor (count, timing, errors)
    - Optional line tracing through the DAG
    - Web dashboard with live stats, traces, and error logs
    """
    
    # Set environment variable for tracing (can be used by other components)
    if trace:
        os.environ['TRACE_ENABLED'] = 'true'
    else:
        os.environ['TRACE_ENABLED'] = 'false'
    
    # Display startup information
    if dashboard:
        typer.echo(f"Starting pipeline with dashboard on http://localhost:{dashboard_port}")
        if trace:
            typer.echo(f"Tracing enabled - storing up to {max_traces} traces")
        else:
            typer.echo("Tracing disabled (use --trace to enable)")
    else:
        typer.echo("Starting pipeline without dashboard")
    
    typer.echo(f"Storing up to {max_errors} errors in memory")
    typer.echo("=" * 60)
    
    # Run the main pipeline
    run(
        input_path=input, 
        config_path=config, 
        output_path=output, 
        trace_enabled=trace,
        dashboard_enabled=dashboard,
        dashboard_port=dashboard_port,
        max_traces=max_traces,
        max_errors=max_errors
    )

if __name__ == "__main__":
    app()


core.py
from typing import Iterator, Tuple, List
from processors.base import BaseProcessor

class ToUppercase(BaseProcessor):
    def process(self, lines: Iterator[str]) -> Iterator[Tuple[List[str], str]]:
        for line in lines:
            yield ["end"], "ERROR: " + line.upper()

class ToSnakecase(BaseProcessor):
    def process(self, lines: Iterator[str]) -> Iterator[Tuple[List[str], str]]:
        for line in lines:
            yield ["end"], "WARN: " + line.replace(" ", "_").lower()

class Trim(BaseProcessor):
    def process(self, lines: Iterator[str]) -> Iterator[Tuple[List[str], str]]:
        for line in lines:
            yield ["end"], "INFO: " + line.strip()

dashboard.py
import time
import threading
from typing import Optional
from fastapi.templating import Jinja2Templates
from fastapi import FastAPI, HTTPException, Query, Request
from starlette.responses import JSONResponse, HTMLResponse
import uvicorn
from metrics import MetricsStore
from pathlib import Path


WATCH_DIR = Path("watch_dir")
UNPROCESSED = WATCH_DIR / "unprocessed"
UNDERPROCESS = WATCH_DIR / "underprocess"
PROCESSED = WATCH_DIR / "processed"

class DashboardServer:
    """FastAPI-based dashboard server for DAG pipeline observability."""
    
    def __init__(self, metrics_store: Optional[MetricsStore] = None):
        self.app = FastAPI(
            title="DAG Pipeline Dashboard", 
            version="1.0.0",
            description="Real-time observability for DAG-based line processing pipeline"
        )
        self.metrics_store = metrics_store or MetricsStore.get_instance()
        self.templates = Jinja2Templates(directory="templates")
        self.setup_routes()
    
    def setup_routes(self):
        """Configure all API routes."""
        
        @self.app.get("/")
        async def root():
            """Root endpoint with API information."""
            return {
                "service": "DAG Pipeline Dashboard",
                "version": "1.0.0",
                "description": "Real-time observability dashboard",
                "endpoints": {
                    "stats": "/stats - Processor statistics with memory metrics",
                    "trace": "/trace - Enhanced line traces with search and filtering",
                    "errors": "/errors - Recent error logs",
                    "processors": "/processors - List all processors with status",
                    "health": "/health - Service health check with memory stats",
                    "dashboard": "/dashboard - HTML dashboard"
                },
                "trace_enabled": self.metrics_store.trace_enabled,
                "timestamp": time.time()
            }
        
        @self.app.get("/stats")
        async def get_stats():
            """Get current processor statistics with memory + file queue metrics."""
            try:
                stats = self.metrics_store.get_stats()
                memory_stats = self.metrics_store.get_memory_stats()
                
                total_lines = sum(p.get("count", 0) for p in stats.values())
                total_errors = sum(p.get("errors", 0) for p in stats.values())
                total_time = sum(p.get("total_time", 0.0) for p in stats.values())
                
                # File queue info
                file_stats = self.metrics_store.get_file_stats(last_n=10)
                file_queue = {
                    "unprocessed": len(list(UNPROCESSED.glob("*"))),
                    "underprocess": len(list(UNDERPROCESS.glob("*"))),
                    "processed": len(list(PROCESSED.glob("*"))),
                    "current_file": file_stats.get("current_file"),
                    "last_processed": file_stats.get("last_processed", [])
                }
                
                return JSONResponse(content={
                    "timestamp": time.time(),
                    "processors": stats,
                    "memory": memory_stats,
                    "summary": {
                        "total_processors": len(stats),
                        "total_lines_processed": total_lines,
                        "total_errors": total_errors,
                        "total_processing_time": round(total_time, 4),
                        "avg_processing_time": round(total_time / max(total_lines, 1), 6),
                        "memory_usage_mb": memory_stats.get("current_memory_mb", 0),
                        "memory_growth_mb": memory_stats.get("memory_growth_mb", 0)
                    },
                    "file_queue": file_queue
                })
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error retrieving stats: {str(e)}")

        
        @self.app.get("/trace")
        async def get_trace(
            limit: int = Query(default=100, ge=1, le=1000, description="Maximum number of traces to return"),
            search: str = Query(default="", description="Search in trace content"),
            processor: str = Query(default="", description="Filter by processor name"),
            tag: str = Query(default="", description="Filter by output tag")
        ):
            """Get recent line traces with enhanced search and filtering."""
            try:
                traces = self.metrics_store.get_traces(
                    limit=limit, 
                    search=search, 
                    processor_filter=processor,
                    tag_filter=tag
                )
                
                return JSONResponse(content={
                    "timestamp": time.time(),
                    "traces": traces,
                    "total_traces": len(traces),
                    "trace_enabled": self.metrics_store.trace_enabled,
                    "filters": {
                        "limit": limit,
                        "search": search,
                        "processor": processor,
                        "tag": tag
                    }
                })
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error retrieving traces: {str(e)}")
        
        @self.app.get("/errors")
        async def get_errors(
            limit: int = Query(default=50, ge=1, le=500, description="Maximum number of errors to return")
        ):
            """Get recent errors."""
            try:
                errors = self.metrics_store.get_errors(limit=limit)
                return JSONResponse(content={
                    "timestamp": time.time(),
                    "errors": errors,
                    "total_errors": len(errors),
                    "limit": limit
                })
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error retrieving errors: {str(e)}")
        
        @self.app.get("/processors")
        async def get_processors():
            """Get list of all processors with their status and basic metrics."""
            try:
                processors = self.metrics_store.get_processors()
                stats = self.metrics_store.get_stats()
                
                # Enrich processor data with detailed metrics
                enriched_processors = []
                for proc in processors:
                    proc_name = proc["name"]
                    if proc_name in stats:
                        detailed_metrics = stats[proc_name]
                        proc.update({
                            "total_time": detailed_metrics.get("total_time", 0.0),
                            "memory_usage_mb": detailed_metrics.get("memory_usage_mb", 0.0)
                        })
                    enriched_processors.append(proc)
                
                return JSONResponse(content={
                    "timestamp": time.time(),
                    "processors": enriched_processors,
                    "total_processors": len(enriched_processors),
                    "active_processors": len([p for p in enriched_processors if p["status"] == "active"]),
                    "idle_processors": len([p for p in enriched_processors if p["status"] == "idle"])
                })
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error retrieving processors: {str(e)}")
        
        @self.app.get("/health")
        async def health_check():
            """Enhanced health check endpoint with memory statistics."""
            try:
                stats = self.metrics_store.get_stats()
                memory_stats = self.metrics_store.get_memory_stats()
                
                return {
                    "status": "healthy",
                    "timestamp": time.time(),
                    "trace_enabled": self.metrics_store.trace_enabled,
                    "active_processors": len(stats),
                    "uptime_seconds": time.time() - getattr(self, '_start_time', time.time()),
                    "memory": memory_stats,
                    "system_health": {
                        "memory_usage_ok": memory_stats.get("memory_percent", 0) < 90,
                        "active_traces": len(self.metrics_store._active_traces) if hasattr(self.metrics_store, '_active_traces') else 0,
                        "stored_traces": len(self.metrics_store.traces),
                        "stored_errors": len(self.metrics_store.errors)
                    }
                }
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error in health check: {str(e)}")
        
        @self.app.get("/dashboard", response_class=HTMLResponse)
        async def get_dashboard(request: Request):
            return self.templates.TemplateResponse("dashboard.html", {"request": request})
    
    def start(self, host: str = "0.0.0.0", port: int = 8000) -> threading.Thread:
        """Start the dashboard server in a background thread."""
        self._start_time = time.time()
        
        def run_server():
            uvicorn.run(
                self.app,
                host=host,
                port=port,
                log_level="error",
                access_log=False
            )
        
        self.server_thread = threading.Thread(target=run_server, daemon=True)
        self.server_thread.start()
        
        # Give server a moment to start
        time.sleep(0.5)
        
        return self.server_thread
    
    def is_running(self) -> bool:
        """Check if the dashboard server is running."""
        return hasattr(self, 'server_thread') and self.server_thread is not None and self.server_thread.is_alive()

# Convenience functions for backwards compatibility
def create_dashboard(metrics_store: Optional[MetricsStore] = None) -> DashboardServer:
    """Create a new dashboard server instance."""
    return DashboardServer(metrics_store)

def start_dashboard(port: int = 8000, metrics_store: Optional[MetricsStore] = None) -> threading.Thread:
    """Start dashboard server and return the thread."""
    dashboard = DashboardServer(metrics_store)
    return dashboard.start(port=port)

main.py
import os
import threading
import time
import uvicorn
import shutil
from pathlib import Path
from typing import Iterator, Optional
from pipeline import build_routing, run_router
from metrics import MetricsStore


def read_lines(path: str) -> Iterator[str]:
    """Read lines from a file, stripping newlines."""
    with open(path, "r") as file:
        for line in file:
            yield line.rstrip("\n")


def write_output(lines: Iterator[str], output_file: Optional[str]) -> None:
    """Write lines to a file or print to console if output_file is None."""
    if output_file is None:
        for line in lines:
            print(line)
    else:
        output_file = os.path.abspath(os.path.expanduser(output_file))
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, "w") as file:
            for line in lines:
                file.write(line + "\n")


# --- Folder queue utilities (Level 8) ---

def ensure_queue_dirs(watch_dir: str) -> dict:
    """Ensure watch_dir has unprocessed, underprocess, and processed folders.

    Returns a dict with Path objects for each folder.
    """
    base = Path(watch_dir).expanduser().resolve()
    unprocessed = base / "unprocessed"
    underprocess = base / "underprocess"
    processed = base / "processed"

    for p in (unprocessed, underprocess, processed):
        p.mkdir(parents=True, exist_ok=True)

    return {"base": base, "unprocessed": unprocessed, "underprocess": underprocess, "processed": processed}


def recover_underprocess(underprocess: Path, unprocessed: Path):
    """Move any files left in underprocess back to unprocessed (recovery on startup)."""
    for item in sorted(underprocess.iterdir()):
        if item.is_file():
            try:
                shutil.move(str(item), str(unprocessed / item.name))
                print(f"Recovered in-progress file back to unprocessed/: {item.name}")
            except Exception as e:
                print(f"Failed to recover {item}: {e}")


def atomic_move_to(src: Path, dest_dir: Path) -> Path:
    """Atomically move src into dest_dir and return new Path."""
    dest = dest_dir / src.name
    shutil.move(str(src), str(dest))
    return dest


def process_file(
    file_path: Path,
    config_path: str,
    metrics_store: MetricsStore,
    output_dir: Path,
):
    """Process a single file line-by-line through the routing engine.

    - Reads lines from file_path
    - Builds routing from config_path
    - Runs router and writes output to output_dir/<filename>.out
    - Updates metrics_store file tracking
    """
    filename = file_path.name
    metrics_store.set_current_file(filename)
    print(f"Processing file: {filename}")

    try:
        # Build routing (load processors)
        nodes = build_routing(config_path)

        # Read lines and run router
        lines = read_lines(str(file_path))

        # Load start tag from config
        import yaml
        with open(config_path, "r") as f:
            cfg = yaml.safe_load(f)
        start_tag = cfg.get("start", "start")

        output_lines = run_router(start_tag, lines, nodes)

        # Write outputs to processed/<filename>.out
        os.makedirs(output_dir, exist_ok=True)
        out_file = output_dir / (filename + ".out")
        write_output(output_lines, str(out_file))

        # Record processed file in metrics
        metrics_store.record_processed_file(filename)
        print(f"Finished processing: {filename}")
        return True

    except Exception as e:
        metrics_store.record_error("file_processor", e, str(file_path))
        print(f"Error processing {filename}: {e}")
        return False

    finally:
        metrics_store.set_current_file(None)


def monitor_folder(
    watch_dir: str,
    config_path: str,
    metrics_store: MetricsStore,
    poll_interval: float = 1.0,
    stop_event: threading.Event | None = None,
):
    """Continuously monitor watch_dir/unprocessed for new files and process them.

    Files are moved to underprocess/ while being worked on and then to processed/ when done.
    """
    paths = ensure_queue_dirs(watch_dir)
    unprocessed = paths["unprocessed"]
    underprocess = paths["underprocess"]
    processed = paths["processed"]

    # On startup, recover any in-progress files
    recover_underprocess(underprocess, unprocessed)

    print(f"Monitoring directory: {unprocessed} for new files...")

    stop_event = stop_event or threading.Event()

    while not stop_event.is_set():
        try:
            # list files in alphabetical/ctime order
            candidates = sorted([p for p in unprocessed.iterdir() if p.is_file()], key=lambda p: p.stat().st_mtime)
            if not candidates:
                time.sleep(poll_interval)
                continue

            for candidate in candidates:
                # Atomically move to underprocess to claim it
                try:
                    claimed = atomic_move_to(candidate, underprocess)
                except Exception as e:
                    print(f"Failed to claim file {candidate.name}: {e}")
                    continue

                # Process file
                ok = process_file(claimed, config_path, metrics_store, processed)

                if ok:
                    # Move processed file to processed/ (we already wrote .out there)
                    try:
                        dest = processed / claimed.name
                        if dest.exists():
                            dest = processed / (claimed.name + ".dup")
                        shutil.move(str(claimed), str(dest))
                    except Exception as e:
                        print(f"Failed to move completed file {claimed.name} to processed/: {e}")
                else:
                    # On failure, move back to unprocessed for retry
                    try:
                        retry_dest = unprocessed / claimed.name
                        if retry_dest.exists():
                            retry_dest = unprocessed / (claimed.name + ".retry")
                        shutil.move(str(claimed), str(retry_dest))
                        print(f"Moved failed file back to unprocessed/ for retry: {claimed.name}")
                    except Exception as e:
                        print(f"Failed to move failed file {claimed.name} back to unprocessed/: {e}")

                # Small pause between files to avoid tight loop
                time.sleep(0.01)

        except Exception as e:
            metrics_store.record_error("monitor", e)
            print(f"Monitor loop error: {e}")
            time.sleep(1.0)

    print("Monitor stopping")


def start_monitor_in_thread(watch_dir: str, config_path: str, metrics_store: MetricsStore) -> tuple[threading.Thread, threading.Event]:
    stop_event = threading.Event()
    thread = threading.Thread(target=monitor_folder, args=(watch_dir, config_path, metrics_store, 1.0, stop_event), daemon=True)
    thread.start()
    return thread, stop_event


def start_dashboard_server(port: int = 8000) -> threading.Thread:
    """Start FastAPI dashboard server in a background thread.

    This function is retained for backwards compatibility but newer code will prefer
    to use the DashboardServer from dashboard.py when available.
    """
    app = FastAPI(title="DAG Pipeline Dashboard", version="1.0.0")
    metrics_store = MetricsStore.get_instance()

    @app.get("/")
    async def root():
        """Root endpoint with basic info."""
        return {
            "message": "DAG Pipeline Dashboard",
            "version": "1.0.0",
            "endpoints": ["/stats", "/trace", "/errors"]
        }

    @app.get("/stats")
    async def get_stats():
        """Get current processor statistics."""
        stats = metrics_store.get_stats()
        file_stats = metrics_store.get_file_stats()
        return {
            "timestamp": time.time(),
            "processors": stats,
            "file_queue": file_stats,
            "summary": {
                "total_processors": len(stats),
                "total_lines_processed": sum(p.get("count", 0) for p in stats.values()),
                "total_errors": sum(p.get("errors", 0) for p in stats.values())
            }
        }

    @app.get("/trace")
    async def get_trace(limit: int = 100):
        """Get recent line traces."""
        traces = metrics_store.get_traces(limit=limit)
        return {
            "timestamp": time.time(),
            "traces": traces,
            "total_traces": len(traces),
            "trace_enabled": metrics_store.trace_enabled
        }

    @app.get("/errors")
    async def get_errors(limit: int = 50):
        """Get recent errors."""
        errors = metrics_store.get_errors(limit=limit)
        return {
            "timestamp": time.time(),
            "errors": errors,
            "total_errors": len(errors)
        }

    def run_server():
        uvicorn.run(app, host="0.0.0.0", port=port, log_level="error", access_log=False)

    # Start server in daemon thread
    thread = threading.Thread(target=run_server, daemon=True)
    thread.start()
    time.sleep(0.5)
    return thread


# --- Public run API (backwards compatible) ---

def run(
    input_path: str,
    config_path: str,
    output_path: Optional[str],
    trace_enabled: bool = False,
    dashboard_enabled: bool = True,
    dashboard_port: int = 8000,
    max_traces: int = 1000,
    max_errors: int = 100,
    watch_dir: Optional[str] = None,
) -> None:
    """Run the tag-based routing engine.

    If watch_dir is provided the system will run in folder-monitor mode. Otherwise
    it behaves like the legacy single-file runner (processing input_path once).
    """
    metrics_store = MetricsStore.get_instance(max_traces=max_traces, max_errors=max_errors)
    metrics_store.set_trace_enabled(trace_enabled)

    dashboard_thread = None
    if dashboard_enabled:
        # Prefer DashboardServer from dashboard.py if available (keeps richer UI)
        try:
            from dashboard import DashboardServer
            dashboard_server = DashboardServer(metrics_store)
            dashboard_thread = dashboard_server.start(port=dashboard_port)
            print(f"Dashboard started at http://localhost:{dashboard_port}")
        except Exception:
            print("Falling back to simple dashboard server")
            dashboard_thread = start_dashboard_server(port=dashboard_port)

    # If watch_dir provided -> start monitor and block
    if watch_dir:
        monitor_thread, stop_event = start_monitor_in_thread(watch_dir, config_path, metrics_store)
        print("File monitor started. Press Ctrl+C to exit.")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("Shutdown requested, stopping monitor...")
            stop_event.set()
            monitor_thread.join(timeout=2.0)
            print("Stopped.")
        return

    # Legacy single-file behavior (process once)
    try:
        print(f"Reading lines from: {input_path}")
        lines = read_lines(input_path)

        print(f"Building routing from: {config_path}")
        nodes = build_routing(config_path)

        # Load start tag from config
        import yaml
        with open(config_path, "r") as f:
            cfg = yaml.safe_load(f)
        start_tag = cfg.get("start", "start")

        print(f"Starting pipeline at tag: {start_tag}")
        if trace_enabled:
            print(f"Tracing enabled (storing {max_traces} traces)")

        output_lines = run_router(start_tag, lines, nodes)

        if output_path:
            print(f"Writing output to: {output_path}")
        else:
            print("Writing output to console")

        write_output(output_lines, output_path)

    except Exception as e:
        metrics_store.record_error("pipeline", e, None)
        print(f"Pipeline error: {e}")
        raise


# Legacy function signature for backwards compatibility
def run_legacy(input_path: str, config_path: str, output_path: Optional[str]) -> None:
    run(input_path, config_path, output_path)


if __name__ == "__main__":
    WATCH_DIR = "watch_dir"
    CONFIG_PATH = "pipeline.yaml"

    run(
        input_path=None,         # not needed in daemon mode
        config_path=CONFIG_PATH,
        output_path=None,        # not needed in daemon mode
        trace_enabled=True,
        dashboard_enabled=True,
        dashboard_port=8000,
        max_traces=1000,
        max_errors=100,
        watch_dir=WATCH_DIR,     # ðŸ‘ˆ enables daemon mode
    )

metrics.py
import threading
import time
import traceback
from collections import deque, defaultdict
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import os
import psutil  # For memory metrics

@dataclass
class TraceStep:
    """Individual step in a line's journey"""
    processor: str
    input_content: str
    output_content: str
    output_tags: List[str]
    timestamp: float
    processing_time: float

@dataclass
class TraceEntry:
    """Enhanced trace entry for a line's journey through the system"""
    line_id: str
    original_content: str
    final_content: str
    steps: List[TraceStep]
    path: List[str]  # sequence of processor tags visited
    all_tags: List[str]  # all output tags generated during journey
    start_timestamp: float
    end_timestamp: float
    total_time: float

@dataclass
class ErrorEntry:
    """Single error entry"""
    processor: str
    message: str
    stack_trace: str
    timestamp: float
    line_content: Optional[str] = None

@dataclass
class ProcessorMetrics:
    """Metrics for a single processor"""
    count: int = 0
    total_time: float = 0.0
    errors: int = 0
    avg_time: float = 0.0
    last_seen: Optional[float] = None
    memory_usage_mb: float = 0.0

class MetricsStore:
    """Thread-safe singleton store for all observability data"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __init__(self, max_traces: int = 1000, max_errors: int = 100):
        self.max_traces = max_traces
        self.max_errors = max_errors
        
        # Metrics per processor
        self.metrics: Dict[str, ProcessorMetrics] = defaultdict(ProcessorMetrics)
        
        # Traces and errors
        self.traces: deque = deque(maxlen=max_traces)
        self.errors: deque = deque(maxlen=max_errors)
        
        # Configuration
        self.trace_enabled = self._get_trace_config()
        
        # Thread safety
        self.mutex = threading.Lock()
        
        # Enhanced line tracking for traces
        self._active_traces: Dict[str, dict] = {}  # line_id -> trace_info
        self._line_counter = 0
        
        # Memory tracking
        try:
            self._process = psutil.Process()
            self._start_memory = self._process.memory_info().rss / 1024 / 1024  # MB
        except Exception:
            self._process = None
            self._start_memory = 0.0

        # File queue tracking (for Level 8)
        self.current_file: Optional[str] = None
        # store (filename, timestamp)
        self._last_processed_files: deque = deque(maxlen=200)

    @classmethod
    def get_instance(cls, max_traces: int = 1000, max_errors: int = 100) -> 'MetricsStore':
        """Get singleton instance"""
        with cls._lock:
            if cls._instance is None:
                cls._instance = MetricsStore(max_traces, max_errors)
            return cls._instance
    
    def _get_trace_config(self) -> bool:
        """Check if tracing is enabled via environment variable"""
        return os.getenv('TRACE_ENABLED', 'false').lower() in ('true', '1', 'yes')
    
    def set_trace_enabled(self, enabled: bool):
        """Enable/disable tracing"""
        with self.mutex:
            self.trace_enabled = enabled
    
    def start_trace(self, line_content: str) -> str:
        """Start tracing a new line, return line_id"""
        if not self.trace_enabled:
            return ""
            
        with self.mutex:
            self._line_counter += 1
            line_id = f"line_{self._line_counter}"
            self._active_traces[line_id] = {
                'original_content': line_content,
                'steps': [],
                'path': [],
                'all_tags': [],
                'start_time': time.time()
            }
            return line_id
    
    def add_trace_step(self, line_id: str, processor_tag: str, input_content: str, 
                      output_content: str, output_tags: List[str], processing_time: float):
        """Add a detailed step to an active trace"""
        if not self.trace_enabled or not line_id:
            return
            
        with self.mutex:
            if line_id in self._active_traces:
                trace_info = self._active_traces[line_id]
                
                step = TraceStep(
                    processor=processor_tag,
                    input_content=input_content,
                    output_content=output_content,
                    output_tags=output_tags,
                    timestamp=time.time(),
                    processing_time=processing_time
                )
                
                trace_info['steps'].append(step)
                trace_info['path'].append(processor_tag)
                trace_info['all_tags'].extend(output_tags)
    
    def complete_trace(self, line_id: str, final_content: str):
        """Complete a trace and store it"""
        if not self.trace_enabled or not line_id:
            return
            
        with self.mutex:
            if line_id in self._active_traces:
                trace_info = self._active_traces.pop(line_id)
                end_time = time.time()
                total_time = end_time - trace_info['start_time']
                
                trace_entry = TraceEntry(
                    line_id=line_id,
                    original_content=trace_info['original_content'],
                    final_content=final_content,
                    steps=trace_info['steps'],
                    path=trace_info['path'],
                    all_tags=list(set(trace_info['all_tags'])),  # Remove duplicates
                    start_timestamp=trace_info['start_time'],
                    end_timestamp=end_time,
                    total_time=total_time
                )
                self.traces.append(trace_entry)
    
    def record_processor_metrics(self, processor_tag: str, execution_time: float, success: bool = True):
        """Record metrics for a processor execution"""
        with self.mutex:
            metrics = self.metrics[processor_tag]
            metrics.count += 1
            metrics.total_time += execution_time
            metrics.avg_time = metrics.total_time / metrics.count
            metrics.last_seen = time.time()
            
            # Update memory usage
            try:
                if self._process is not None:
                    current_memory = self._process.memory_info().rss / 1024 / 1024  # MB
                    metrics.memory_usage_mb = current_memory - self._start_memory
            except Exception:
                pass  # Ignore memory tracking errors
            
            if not success:
                metrics.errors += 1
    
    def record_error(self, processor_tag: str, error: Exception, line_content: Optional[str] = None):
        """Record an error"""
        with self.mutex:
            error_entry = ErrorEntry(
                processor=processor_tag,
                message=str(error),
                stack_trace=traceback.format_exc(),
                timestamp=time.time(),
                line_content=line_content
            )
            self.errors.append(error_entry)
            
            # Also update processor error count
            self.metrics[processor_tag].errors += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """Get current statistics"""
        with self.mutex:
            return {
                processor: asdict(metrics)
                for processor, metrics in self.metrics.items()
            }
    
    def get_traces(self, limit: int = 100, search: str = "", processor_filter: str = "", 
                   tag_filter: str = "") -> List[Dict[str, Any]]:
        """Get recent traces with search and filter capabilities"""
        with self.mutex:
            traces = list(self.traces)
            
            # Apply filters
            if search:
                search_lower = search.lower()
                traces = [
                    t for t in traces 
                    if (search_lower in t.original_content.lower() or 
                        search_lower in t.final_content.lower() or
                        any(search_lower in step.input_content.lower() or 
                            search_lower in step.output_content.lower() 
                            for step in t.steps))
                ]
            
            if processor_filter:
                traces = [t for t in traces if processor_filter in t.path]
            
            if tag_filter:
                traces = [t for t in traces if tag_filter in t.all_tags]
            
            # Get most recent and convert to dict
            recent_traces = traces[-limit:] if traces else []
            return [asdict(trace) for trace in recent_traces]
    
    def get_errors(self, limit: int = 50) -> List[Dict[str, Any]]:
        """Get recent errors"""
        with self.mutex:
            errors = list(self.errors)[-limit:]
            return [asdict(error) for error in errors]
    
    def get_memory_stats(self) -> Dict[str, float]:
        """Get current memory statistics"""
        try:
            if self._process is None:
                return {
                    "current_memory_mb": 0,
                    "peak_memory_mb": 0, 
                    "memory_percent": 0,
                    "start_memory_mb": self._start_memory,
                    "memory_growth_mb": 0
                }
            memory_info = self._process.memory_info()
            peak = 0
            if hasattr(memory_info, 'peak_wset'):
                peak = memory_info.peak_wset / 1024 / 1024
            return {
                "current_memory_mb": memory_info.rss / 1024 / 1024,
                "peak_memory_mb": peak,
                "memory_percent": self._process.memory_percent(),
                "start_memory_mb": self._start_memory,
                "memory_growth_mb": (memory_info.rss / 1024 / 1024) - self._start_memory
            }
        except Exception:
            return {
                "current_memory_mb": 0,
                "peak_memory_mb": 0, 
                "memory_percent": 0,
                "start_memory_mb": self._start_memory,
                "memory_growth_mb": 0
            }
    
    def get_processors(self) -> List[Dict[str, Any]]:
        """Get list of all processors with their basic info"""
        with self.mutex:
            processors = []
            for processor_tag, metrics in self.metrics.items():
                processors.append({
                    "name": processor_tag,
                    "count": metrics.count,
                    "errors": metrics.errors,
                    "avg_time": metrics.avg_time,
                    "last_seen": metrics.last_seen,
                    "status": "active" if metrics.last_seen and (time.time() - metrics.last_seen) < 60 else "idle"
                })
            return sorted(processors, key=lambda x: x["name"])
    
    def clear_metrics(self):
        """Clear all metrics (useful for testing)"""
        with self.mutex:
            self.metrics.clear()
            self.traces.clear()
            self.errors.clear()
            self._active_traces.clear()
            self._line_counter = 0
            self.current_file = None
            self._last_processed_files.clear()

    # ------------------ File queue tracking API (Level 8) ------------------
    def set_current_file(self, filename: Optional[str]):
        """Set the filename currently being processed (or None)."""
        with self.mutex:
            self.current_file = filename
    
    def record_processed_file(self, filename: str):
        """Record a file that finished processing successfully with timestamp."""
        with self.mutex:
            self._last_processed_files.append((filename, time.time()))
            # clear current file if it matches
            if self.current_file == filename:
                self.current_file = None
    
    def get_file_stats(self, last_n: int = 10) -> Dict[str, Any]:
        """Return file-related stats for dashboard consumption."""
        with self.mutex:
            last = list(self._last_processed_files)[-last_n:]
            return {
                "current_file": self.current_file,
                "last_processed": [
                    {"filename": fn, "timestamp": ts} for fn, ts in reversed(last)
                ]
            }

    def list_last_processed(self, n: int = 10) -> List[Tuple[str, float]]:
        with self.mutex:
            return list(self._last_processed_files)[-n:]

pipeline.py
# pipeline.py
import yaml
import importlib
from typing import Any, Iterator, Tuple, List, Dict
from typez import ProcessorFn
import networkx as nx
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from metrics import MetricsStore

class ProcessorNode:
    def __init__(self, tag: str, processor: ProcessorFn):
        self.tag = tag
        self.processor = processor
        self.graph: nx.DiGraph | None = None  # optional graph reference
        
        # Set processor tag for metrics if it's a BaseProcessor instance
        if hasattr(processor, 'set_processor_tag'):
            processor.set_processor_tag(tag)

def load_function(import_path: str) -> ProcessorFn:
    module_path, name = import_path.rsplit(".", 1)
    module = importlib.import_module(module_path)
    obj = getattr(module, name)
    if isinstance(obj, type):
        obj = obj()
    if not callable(obj):
        raise TypeError(f"Processor '{import_path}' is not callable")
    return obj

def build_routing(config_path: str) -> Dict[str, ProcessorNode]:
    with open(config_path, "r") as f:
        config: dict[str, Any] = yaml.safe_load(f)
    
    nodes: Dict[str, ProcessorNode] = {}
    metrics_store = MetricsStore.get_instance()
    
    for node_cfg in config.get("nodes", []):
        tag = node_cfg["tag"]
        processor = load_function(node_cfg["type"])
        
        # Create processor node and set tag for metrics
        nodes[tag] = ProcessorNode(tag, processor)
        
        # Initialize processor metrics
        metrics_store.record_processor_metrics(tag, 0.0, True)
    
    if "start" not in nodes:
        raise ValueError("Config must include a 'start' node")
    if "end" not in nodes:
        raise ValueError("Config must include an 'end' node")
    
    graph = nx.DiGraph()
    for tag in nodes:
        graph.add_node(tag)
    
    for node_cfg in config.get("nodes", []):
        tag = node_cfg["tag"]
        for out_tag in node_cfg.get("routes", []):
            if out_tag not in nodes and out_tag != "end":
                raise KeyError(f"Node '{tag}' declares route to unknown tag '{out_tag}'")
            graph.add_edge(tag, out_tag)
    
    unreachable = set(nodes) - set(nx.descendants(graph, "start")) - {"start"}
    if unreachable:
        print(f"Warning: unreachable nodes from 'start': {unreachable}")
    
    try:
        cycles = list(nx.find_cycle(graph, orientation="original"))
        if cycles:
            print(f"Warning: detected cycles in routing graph: {cycles}")
    except nx.exception.NetworkXNoCycle:
        pass
    
    for node in nodes.values():
        node.graph = graph
    
    return nodes

def visualize_routing(nodes: Dict[str, ProcessorNode], title: str = "Routing Graph", output_file: str | None = None) -> None:
    """
    Visualize the routing graph using networkx and matplotlib.
    If output_file is provided, saves the figure instead of showing it.
    """
    any_node = next(iter(nodes.values()))
    graph = any_node.graph
    if graph is None:
        print("No graph available for visualization.")
        return
    
    plt.figure(figsize=(8, 6))
    pos = nx.spring_layout(graph)
    nx.draw(graph, pos, with_labels=True, node_color="skyblue", node_size=2000, edge_color="gray", arrowsize=20)
    plt.title(title)
    
    if output_file:
        plt.savefig(output_file)
        print(f"Graph saved to {output_file}")
    else:
        plt.show()

def run_router(start_tag: str, lines: Iterator[str], nodes: Dict[str, ProcessorNode], max_hops: int = 1000) -> Iterator[str]:
    from collections import deque
    import time
    
    metrics_store = MetricsStore.get_instance()
    
    # Track routing-level metrics
    routing_start_time = time.time()
    total_lines_processed = 0
    
    pending = deque([(start_tag, line, 0, "") for line in lines])
    
    while pending:
        tag, line, hops, line_id = pending.popleft()
        
        if tag == "end":
            # Complete the trace if we have a line_id - FIXED VERSION
            if line_id and metrics_store.trace_enabled:
                # Provide all required parameters for enhanced add_trace_step
                metrics_store.add_trace_step(
                    line_id=line_id,
                    processor_tag="end",
                    input_content=line,
                    output_content=line,
                    output_tags=["end"],
                    processing_time=0.0
                )
                metrics_store.complete_trace(line_id, line)
            
            total_lines_processed += 1
            yield line
            continue
        
        if hops > max_hops:
            error_msg = f"Line exceeded max hops ({max_hops}) for tag '{tag}'. Possible infinite loop."
            metrics_store.record_error("router", Exception(error_msg), line)
            raise RuntimeError(error_msg)
        
        if tag not in nodes:
            error_msg = f"Line routed to unknown tag '{tag}'. Please check processor output or config."
            metrics_store.record_error("router", KeyError(error_msg), line)
            raise KeyError(error_msg)
        
        processor_node = nodes[tag]
        
        try:
            # Start trace for this line if not already started
            if not line_id and metrics_store.trace_enabled:
                line_id = metrics_store.start_trace(line)
            
            # Process the line through the current processor
            for out_tags, out_line in processor_node.processor(iter([line])):
                # Validate processor output
                if not isinstance(out_tags, list):
                    error_msg = f"Processor '{tag}' must yield a list of tags, got {type(out_tags).__name__}"
                    metrics_store.record_error(tag, TypeError(error_msg), line)
                    raise TypeError(error_msg)
                
                if not out_tags:
                    error_msg = f"Processor '{tag}' yielded an empty list of tags. Each line must have at least one tag."
                    metrics_store.record_error(tag, ValueError(error_msg), line)
                    raise ValueError(error_msg)
                
                for out_tag in out_tags:
                    if out_tag not in nodes and out_tag != "end":
                        error_msg = f"Processor '{tag}' emitted unknown tag '{out_tag}'. Add it to config."
                        metrics_store.record_error(tag, KeyError(error_msg), line)
                        raise KeyError(error_msg)
                    
                    # Add to pending with the same line_id for tracing continuity
                    pending.append((out_tag, out_line, hops + 1, line_id))
                    
        except Exception as e:
            # Error already recorded by BaseProcessor, just re-raise
            raise e
    
    # Record overall routing metrics
    total_routing_time = time.time() - routing_start_time
    print(f"Routing completed: {total_lines_processed} lines in {total_routing_time:.2f}s")

pipeline.yaml
start: start

nodes:
  - tag: start
    type: processors.tagger.Tagger
    routes:
      - error
      - warn
      - trimmed

  - tag: error
    type: core.ToUppercase
    routes:
      - end

  - tag: trimmed
    type: core.Trim
    routes:
      - end

  - tag: warn
    type: core.ToSnakecase
    routes:
      - end

  - tag: end
    type: processors.output.Terminal
    routes: []


